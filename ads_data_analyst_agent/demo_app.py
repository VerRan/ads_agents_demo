import streamlit as st
import pandas as pd
import os
import io
import json
import time
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="AIæ•°æ®åˆ†æå¸ˆæ¼”ç¤º",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .demo-card {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .stButton > button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        border-radius: 5px;
        border: none;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .analysis-status {
        background-color: #f0f8ff;
        padding: 0.8rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
        font-size: 0.9rem;
    }
    .code-execution {
        background-color: #f5f5f5;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .metric-compact {
        text-align: center;
        padding: 0.5rem;
        background-color: #f8f9fa;
        border-radius: 5px;
        margin: 0.2rem;
        font-size: 0.85rem;
    }
    .status-row {
        background-color: #fafafa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []
if 'current_file_name' not in st.session_state:
    st.session_state.current_file_name = None

def load_default_data():
    """Load default Google Ads data"""
    try:
        data_path = "google.campaign_daily_geo_stats.csv"
        if os.path.exists(data_path):
            df = pd.read_csv(data_path)
            if 'data_day' in df.columns:
                df['data_day'] = pd.to_datetime(df['data_day'])
            if 'fetch_time' in df.columns:
                df['fetch_time'] = pd.to_datetime(df['fetch_time'])
            return df, "google.campaign_daily_geo_stats.csv"
        return None, None
    except Exception as e:
        st.error(f"åŠ è½½é»˜è®¤æ•°æ®å¤±è´¥: {str(e)}")
        return None, None

def create_analysis_report_text(query, result, file_name):
    """åˆ›å»ºæ–‡æœ¬æ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
    report = f"""# æ•°æ®åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **åˆ†ææ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ–‡ä»¶:** {file_name}
- **åˆ†æé—®é¢˜:** {query}

## åˆ†æç»“æœ

{result}

---
æŠ¥å‘Šç”±AIæ•°æ®åˆ†æå¸ˆç”Ÿæˆ
"""
    return report

def create_json_report(analysis_data):
    """åˆ›å»ºJSONæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
    try:
        report_data = {
            "analysis_time": datetime.now().isoformat(),
            "file_name": analysis_data.get('file_name', ''),
            "query": analysis_data.get('query', ''),
            "result": analysis_data.get('result', ''),
            "metadata": {
                "tool": "AIæ•°æ®åˆ†æå¸ˆ",
                "version": "1.0"
            }
        }
        return json.dumps(report_data, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"åˆ›å»ºJSONæŠ¥å‘Šå¤±è´¥: {str(e)}")
        return None

def create_csv_summary(data):
    """åˆ›å»ºCSVæ ¼å¼çš„æ•°æ®æ‘˜è¦"""
    try:
        summary_data = []
        
        # åŸºæœ¬ä¿¡æ¯
        summary_data.append(['æ•°æ®é¡¹', 'å€¼'])
        summary_data.append(['æ€»è¡Œæ•°', len(data)])
        summary_data.append(['æ€»åˆ—æ•°', len(data.columns)])
        summary_data.append(['ç¼ºå¤±å€¼æ€»æ•°', data.isnull().sum().sum()])
        summary_data.append(['æ•°å€¼åˆ—æ•°é‡', len(data.select_dtypes(include=['number']).columns)])
        summary_data.append([''])
        
        # åˆ—ä¿¡æ¯
        summary_data.append(['åˆ—å', 'æ•°æ®ç±»å‹', 'ç¼ºå¤±å€¼æ•°é‡', 'å”¯ä¸€å€¼æ•°é‡'])
        for col in data.columns:
            summary_data.append([
                col,
                str(data[col].dtype),
                data[col].isnull().sum(),
                data[col].nunique()
            ])
        
        # è½¬æ¢ä¸ºDataFrame
        max_cols = max(len(row) for row in summary_data)
        for row in summary_data:
            while len(row) < max_cols:
                row.append('')
        
        df_summary = pd.DataFrame(summary_data)
        
        # è½¬æ¢ä¸ºCSV
        csv_buffer = io.StringIO()
        df_summary.to_csv(csv_buffer, index=False, header=False, encoding='utf-8')
        
        return csv_buffer.getvalue()
    except Exception as e:
        st.error(f"åˆ›å»ºCSVæ‘˜è¦å¤±è´¥: {str(e)}")
        return None

def create_history_export(analysis_history):
    """åˆ›å»ºåˆ†æå†å²çš„å¯¼å‡ºæ–‡ä»¶"""
    try:
        export_data = {
            "export_time": datetime.now().isoformat(),
            "total_analyses": len(analysis_history),
            "analyses": []
        }
        
        for analysis in analysis_history:
            export_data["analyses"].append({
                "timestamp": analysis['timestamp'].isoformat(),
                "file_name": analysis.get('file_name', ''),
                "query": analysis['query'],
                "result": analysis['result']
            })
        
        return json.dumps(export_data, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"åˆ›å»ºå†å²å¯¼å‡ºå¤±è´¥: {str(e)}")
        return None

def analyze_code_purpose(code):
    """åˆ†æä»£ç çš„ç›®çš„å’ŒåŠŸèƒ½"""
    code_lower = code.lower()
    
    if 'import' in code_lower:
        return "å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—"
    elif 'read_csv' in code_lower or 'pd.read' in code_lower:
        return "è¯»å–å’ŒåŠ è½½æ•°æ®æ–‡ä»¶"
    elif 'describe()' in code_lower:
        return "ç”Ÿæˆæ•°æ®çš„æè¿°æ€§ç»Ÿè®¡"
    elif 'info()' in code_lower:
        return "æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯"
    elif 'head()' in code_lower or 'tail()' in code_lower:
        return "æŸ¥çœ‹æ•°æ®æ ·æœ¬"
    elif 'isnull()' in code_lower or 'isna()' in code_lower:
        return "æ£€æŸ¥ç¼ºå¤±å€¼"
    elif 'groupby' in code_lower:
        return "æŒ‰æ¡ä»¶åˆ†ç»„åˆ†ææ•°æ®"
    elif 'plot' in code_lower or 'plt.' in code_lower:
        return "åˆ›å»ºæ•°æ®å¯è§†åŒ–å›¾è¡¨"
    elif 'corr()' in code_lower:
        return "è®¡ç®—ç›¸å…³æ€§åˆ†æ"
    elif 'value_counts()' in code_lower:
        return "ç»Ÿè®¡æ•°å€¼åˆ†å¸ƒ"
    elif 'mean()' in code_lower or 'sum()' in code_lower or 'count()' in code_lower:
        return "è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"
    elif 'merge' in code_lower or 'join' in code_lower:
        return "åˆå¹¶å’Œè¿æ¥æ•°æ®"
    elif 'drop' in code_lower:
        return "åˆ é™¤ä¸éœ€è¦çš„æ•°æ®"
    elif 'fillna' in code_lower:
        return "å¤„ç†ç¼ºå¤±å€¼"
    else:
        return "æ‰§è¡Œæ•°æ®åˆ†ææ“ä½œ"

def estimate_code_complexity(code):
    """ä¼°ç®—ä»£ç å¤æ‚åº¦"""
    lines = code.split('\n')
    non_empty_lines = [line for line in lines if line.strip()]
    
    complexity_score = 0
    
    # åŸºç¡€å¤æ‚åº¦ï¼šè¡Œæ•°
    complexity_score += len(non_empty_lines)
    
    # å¾ªç¯å’Œæ¡ä»¶è¯­å¥å¢åŠ å¤æ‚åº¦
    for line in non_empty_lines:
        line_lower = line.lower()
        if any(keyword in line_lower for keyword in ['for ', 'while ', 'if ', 'elif ', 'try:', 'except']):
            complexity_score += 2
        if any(keyword in line_lower for keyword in ['groupby', 'merge', 'join', 'pivot']):
            complexity_score += 3
        if any(keyword in line_lower for keyword in ['plot', 'figure', 'subplot']):
            complexity_score += 2
    
    if complexity_score <= 5:
        return "ç®€å• ğŸŸ¢"
    elif complexity_score <= 15:
        return "ä¸­ç­‰ ğŸŸ¡"
    else:
        return "å¤æ‚ ğŸ”´"

def format_code_result(result, code):
    """æ ¼å¼åŒ–ä»£ç æ‰§è¡Œç»“æœ"""
    if not result:
        return "ä»£ç æ‰§è¡Œå®Œæˆï¼Œæ— è¾“å‡ºç»“æœ"
    
    result_str = str(result)
    
    # å¦‚æœç»“æœå¤ªé•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
    if len(result_str) > 1000:
        lines = result_str.split('\n')
        if len(lines) > 20:
            # æ˜¾ç¤ºå‰10è¡Œå’Œå5è¡Œ
            truncated = '\n'.join(lines[:10]) + '\n\n... (çœç•¥ä¸­é—´éƒ¨åˆ†) ...\n\n' + '\n'.join(lines[-5:])
            return f"```\n{truncated}\n```\n\n*å®Œæ•´ç»“æœå…±{len(lines)}è¡Œï¼Œå·²æ™ºèƒ½æˆªæ–­æ˜¾ç¤º*"
        else:
            # æŒ‰å­—ç¬¦æˆªæ–­
            return f"```\n{result_str[:500]}\n\n... (ç»“æœå¤ªé•¿ï¼Œå·²æˆªæ–­) ...\n\n{result_str[-200:]}\n```"
    else:
        return f"```\n{result_str}\n```"

def get_execution_time_estimate(code):
    """ä¼°ç®—ä»£ç æ‰§è¡Œæ—¶é—´"""
    code_lower = code.lower()
    
    if any(keyword in code_lower for keyword in ['read_csv', 'read_excel', 'read_sql']):
        return "é¢„è®¡ 2-5ç§’ (æ•°æ®è¯»å–)"
    elif any(keyword in code_lower for keyword in ['groupby', 'merge', 'join']):
        return "é¢„è®¡ 1-3ç§’ (æ•°æ®å¤„ç†)"
    elif any(keyword in code_lower for keyword in ['plot', 'figure', 'subplot']):
        return "é¢„è®¡ 1-2ç§’ (å›¾è¡¨ç”Ÿæˆ)"
    elif any(keyword in code_lower for keyword in ['describe', 'info', 'head', 'tail']):
        return "é¢„è®¡ <1ç§’ (å¿«é€ŸæŸ¥çœ‹)"
    else:
        return "é¢„è®¡ 1-2ç§’ (ä¸€èˆ¬æ“ä½œ)"

def create_streaming_agent(content_placeholder, status_placeholder, code_stats_placeholder=None):
    """åˆ›å»ºæ”¯æŒæµå¼è¾“å‡ºçš„ä»£ç†"""
    
    def streaming_callback(**kwargs):
        try:
            # æ‰“å°æ‰€æœ‰å›è°ƒä¿¡æ¯ç”¨äºè°ƒè¯•
            print(f"ğŸ”” Callback received: {list(kwargs.keys())}")
            for key, value in kwargs.items():
                print(f"  {key}: {str(value)[:100]}...")
            
            # å¤„ç†æ‰€æœ‰ç±»å‹çš„å›è°ƒ
            for key, value in kwargs.items():
                # å¤„ç†æ–‡æœ¬æ•°æ®
                if key in ['data', 'text'] and value:
                    if hasattr(streaming_callback, 'content'):
                        streaming_callback.content += str(value)
                    else:
                        streaming_callback.content = str(value)
                    
                    content_placeholder.markdown(streaming_callback.content)
                    
                    # æ›´æ–°çŠ¶æ€
                    preview = str(value).strip()[:50]
                    if preview:
                        status_placeholder.info(f"ğŸ’¬ AIè¾“å‡º: {preview}...")
                
                # å¤„ç†å·¥å…·ç›¸å…³çš„å›è°ƒ
                elif 'tool' in key.lower() or 'python' in str(value).lower():
                    print(f"ğŸ”§ Tool-related callback: {key} = {value}")
                    
                    # å°è¯•è§£æå·¥å…·ä¿¡æ¯
                    if isinstance(value, dict):
                        tool_name = value.get('name', value.get('tool', 'unknown'))
                        tool_input = value.get('input', value.get('tool_input', {}))
                        
                        if 'python' in tool_name.lower() or 'repl' in tool_name.lower():
                            # å¤„ç†Pythonä»£ç æ‰§è¡Œ
                            if isinstance(tool_input, dict) and 'code' in tool_input:
                                code = str(tool_input['code'])
                                
                                streaming_callback.code_execution_count += 1
                                code_purpose = analyze_code_purpose(code)
                                code_complexity = estimate_code_complexity(code)
                                time_estimate = get_execution_time_estimate(code)
                                
                                code_display = f"""
---
**ğŸ æ­£åœ¨æ‰§è¡ŒPythonä»£ç  (ç¬¬{streaming_callback.code_execution_count}æ­¥):**

ğŸ“‹ **ä»£ç ä¿¡æ¯:**
- ç›®çš„: {code_purpose}
- å¤æ‚åº¦: {code_complexity}
- é¢„è®¡ç”¨æ—¶: {time_estimate}

```python
{code}
```

â³ æ‰§è¡Œä¸­ï¼Œè¯·ç¨å€™...
"""
                                if hasattr(streaming_callback, 'content'):
                                    streaming_callback.content += code_display
                                else:
                                    streaming_callback.content = code_display
                                content_placeholder.markdown(streaming_callback.content)
                                
                                # æ›´æ–°ç»Ÿè®¡
                                if hasattr(streaming_callback, 'code_stats_placeholder') and streaming_callback.code_stats_placeholder:
                                    streaming_callback.code_stats_placeholder.markdown(f'<div class="analysis-status"><strong>ğŸ ç¬¬{streaming_callback.code_execution_count}æ­¥:</strong><br/>{code_purpose} â³</div>', unsafe_allow_html=True)
                                
                                status_placeholder.info(f"ğŸ æ‰§è¡Œä»£ç : {code.split(chr(10))[0][:50]}...")
                                streaming_callback.last_code_start = datetime.now()
                    
                    elif isinstance(value, str) and len(value) > 10:
                        # å¯èƒ½æ˜¯å·¥å…·æ‰§è¡Œç»“æœ
                        result_display = f"""
**ğŸ“Š æ‰§è¡Œç»“æœ:**

```
{value}
```

---
"""
                        if hasattr(streaming_callback, 'content'):
                            streaming_callback.content += result_display
                        else:
                            streaming_callback.content = result_display
                        content_placeholder.markdown(streaming_callback.content)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        if hasattr(streaming_callback, 'code_stats_placeholder') and streaming_callback.code_stats_placeholder:
                            execution_time = (datetime.now() - streaming_callback.last_code_start).total_seconds() if hasattr(streaming_callback, 'last_code_start') else 0
                            streaming_callback.code_stats_placeholder.markdown(f'<div class="analysis-status"><strong>ğŸ å®Œæˆ{streaming_callback.code_execution_count}æ­¥:</strong><br/>ç”¨æ—¶{execution_time:.1f}ç§’ âœ…</div>', unsafe_allow_html=True)
                        
                        status_placeholder.success(f"âœ… æ‰§è¡Œå®Œæˆ: {str(value)[:50]}...")
                
                # å¤„ç†å…¶ä»–ç±»å‹çš„å›è°ƒ
                else:
                    if st.session_state.get('debug_mode', False):
                        print(f"Other callback: {key} = {str(value)[:100]}...")
                    
        except Exception as e:
            error_msg = f"å›è°ƒå‡½æ•°é”™è¯¯: {e}"
            print(error_msg)
            if st.session_state.get('debug_mode', False):
                st.error(error_msg)
    
    # åˆå§‹åŒ–å†…å®¹å’Œå·¥å…·è·Ÿè¸ª
    streaming_callback.content = ""
    streaming_callback.code_execution_count = 0
    streaming_callback.current_step = "å‡†å¤‡ä¸­"
    streaming_callback.code_stats_placeholder = code_stats_placeholder
    
    # åŠ¨æ€å¯¼å…¥agentç»„ä»¶
    try:
        from google_ads_anlyst_agent import get_llm
        from strands import Agent
        from strands_tools import file_read, python_repl
        
        # åˆ›å»ºæµå¼ä»£ç† - ç›´æ¥ä½¿ç”¨å›è°ƒå‡½æ•°
        streaming_agent = Agent(
            model=get_llm(),
            system_prompt="""
ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ•°æ®åˆ†æä¸“å®¶å’ŒPythonç¼–ç¨‹ä¸“å®¶ï¼Œè¯·å¸®æˆ‘ç¼–å†™ä»£ç å®Œæˆæ•°æ®åˆ†æä»»åŠ¡ã€‚

è¯·è¯¦ç»†è¯´æ˜åˆ†æè¿‡ç¨‹ï¼ŒåŒ…æ‹¬:
1. æ•°æ®åŠ è½½å’ŒåŸºæœ¬ä¿¡æ¯æŸ¥çœ‹
2. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†æ­¥éª¤  
3. é€æ­¥çš„åˆ†æè¿‡ç¨‹ï¼Œæ¯æ­¥é™„æœ‰è¯¦ç»†è¯´æ˜
4. å…³é”®å‘ç°å’Œæ´å¯Ÿ
5. ç»“è®ºå’Œå»ºè®®

è¯·ç¡®ä¿åˆ†æè¿‡ç¨‹æ¸…æ™°æ˜“æ‡‚ï¼Œç»“æœå‡†ç¡®å¯é ã€‚åœ¨æ‰§è¡Œæ¯ä¸ªæ­¥éª¤æ—¶ï¼Œè¯·è¯¦ç»†è§£é‡Šä½ åœ¨åšä»€ä¹ˆã€‚
            """,
            tools=[file_read, python_repl],
            callback_handler=streaming_callback
        )
        
        return streaming_agent, streaming_callback
        
    except Exception as e:
        st.error(f"åˆ›å»ºæµå¼ä»£ç†å¤±è´¥: {str(e)}")
        return None, None

def analyze_data_with_agent_streaming(query, data_file_name, content_placeholder, status_placeholder):
    """ä½¿ç”¨AIä»£ç†è¿›è¡Œæµå¼åˆ†æ"""
    try:
        # æ­¥éª¤1: åˆ›å»ºæµå¼ä»£ç†
        status_placeholder.info("ğŸ”§ æ­£åœ¨åˆ›å»ºAIåˆ†æä»£ç†...")
        streaming_agent, callback = create_streaming_agent(content_placeholder, status_placeholder)
        
        if streaming_agent is None:
            status_placeholder.warning("âš ï¸ æµå¼ä»£ç†åˆ›å»ºå¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å¼...")
            return analyze_data_fallback(query, data_file_name, content_placeholder, status_placeholder)
        
        # æ­¥éª¤2: æ„å»ºæŸ¥è¯¢
        status_placeholder.info("ğŸ“ æ­£åœ¨æ„å»ºåˆ†ææŸ¥è¯¢...")
        full_query = f"å½“å‰ç›®å½•{data_file_name}çš„æ–‡ä»¶ï¼Œ{query}"
        
        # æ­¥éª¤3: åˆå§‹åŒ–æ˜¾ç¤º
        status_placeholder.info("ğŸš€ AIåˆ†æä»£ç†å·²å¯åŠ¨ï¼Œå¼€å§‹åˆ†æ...")
        content_placeholder.markdown("**ğŸ¤– AIåˆ†æè¿‡ç¨‹:**\n\nğŸ” AIæ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜...\n")
        
        # æ­¥éª¤4: æ‰§è¡Œæµå¼åˆ†æ
        status_placeholder.info("ğŸ§  AIæ­£åœ¨æ€è€ƒå’Œåˆ†æ...")
        result = streaming_agent(full_query)
        
        # æ­¥éª¤5: å¤„ç†ç»“æœ
        status_placeholder.info("ğŸ“Š æ­£åœ¨æ•´ç†åˆ†æç»“æœ...")
        final_content = callback.content if callback.content else str(result)
        
        # å¦‚æœæ²¡æœ‰æµå¼å†…å®¹ï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
        if not callback.content and result:
            final_content = f"**ğŸ¯ æœ€ç»ˆåˆ†æç»“æœ:**\n\n{str(result)}"
            content_placeholder.markdown(final_content)
        else:
            # æ·»åŠ ç»“æŸæ ‡è®°
            if hasattr(callback, 'content') and callback.content:
                callback.content += "\n\n---\n**âœ… åˆ†æå®Œæˆ**"
                content_placeholder.markdown(callback.content)
        
        return final_content
        
    except Exception as e:
        error_msg = f"æµå¼åˆ†æå¤±è´¥: {str(e)}"
        print(error_msg)
        status_placeholder.warning("âš ï¸ æµå¼åˆ†æé‡åˆ°é—®é¢˜ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å¼...")
        return analyze_data_fallback(query, data_file_name, content_placeholder, status_placeholder)

def analyze_data_with_agent_streaming_with_progress(query, data_file_name, content_placeholder, status_placeholder, progress_placeholder, time_placeholder, code_stats_placeholder, start_time):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„æµå¼åˆ†æ"""
    try:
        # æ­¥éª¤1: åˆ›å»ºä»£ç† (20%)
        progress_placeholder.progress(0.2)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - åˆ›å»ºAIä»£ç†")
        
        streaming_agent, callback = create_streaming_agent(content_placeholder, status_placeholder, code_stats_placeholder)
        
        if streaming_agent is None:
            return analyze_data_fallback_with_progress(query, data_file_name, content_placeholder, status_placeholder, progress_placeholder, time_placeholder, code_stats_placeholder, start_time)
        
        # æ­¥éª¤2: å‡†å¤‡æŸ¥è¯¢ (40%)
        progress_placeholder.progress(0.4)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - å‡†å¤‡æŸ¥è¯¢")
        
        full_query = f"å½“å‰ç›®å½•{data_file_name}çš„æ–‡ä»¶ï¼Œ{query}"
        content_placeholder.markdown("**ğŸ¤– AIåˆ†æè¿‡ç¨‹:**\n\nğŸ” AIæ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜...\n")
        
        # æ­¥éª¤3: æ‰§è¡Œåˆ†æ (60%-90%)
        progress_placeholder.progress(0.6)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - æ‰§è¡Œåˆ†æ")
        
        result = streaming_agent(full_query)
        
        # æ­¥éª¤4: å®Œæˆ (100%)
        progress_placeholder.progress(1.0)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - å®Œæˆ")
        
        final_content = callback.content if callback.content else str(result)
        
        if not callback.content and result:
            final_content = f"**ğŸ¯ æœ€ç»ˆåˆ†æç»“æœ:**\n\n{str(result)}"
            content_placeholder.markdown(final_content)
        else:
            if hasattr(callback, 'content') and callback.content:
                callback.content += "\n\n---\n**âœ… åˆ†æå®Œæˆ**"
                content_placeholder.markdown(callback.content)
        
        return final_content
        
    except Exception as e:
        error_msg = f"æµå¼åˆ†æå¤±è´¥: {str(e)}"
        print(error_msg)
        return analyze_data_fallback_with_progress(query, data_file_name, content_placeholder, status_placeholder, progress_placeholder, time_placeholder, start_time)

def analyze_data_fallback(query, data_file_name, content_placeholder, status_placeholder):
    """å¤‡ç”¨çš„éæµå¼åˆ†ææ–¹æ³•"""
    try:
        # æ­¥éª¤1: å¯¼å…¥AIä»£ç†
        status_placeholder.info("ğŸ”§ æ­£åœ¨åŠ è½½AIåˆ†æå¼•æ“ï¼ˆå¤‡ç”¨æ¨¡å¼ï¼‰...")
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–AIåˆ†æå¼•æ“...")
        
        from google_ads_anlyst_agent import agent
        
        # æ­¥éª¤2: æ„å»ºæŸ¥è¯¢
        status_placeholder.info("ï¿½ æ­£åœ¨å‡†å¤‡åˆ†ææŸ¥è¯¢ï¼ˆ...")
        full_query = f"å½“å‰ç›®å½•{data_file_name}çš„æ–‡ä»¶ï¼Œ{query}"
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ“ æŸ¥è¯¢å·²å‡†å¤‡å®Œæˆ\n\nğŸ§  AIæ­£åœ¨æ·±åº¦åˆ†ææ‚¨çš„æ•°æ®...")
        
        # æ­¥éª¤3: æ‰§è¡Œåˆ†æ
        status_placeholder.info("ğŸ§  AIæ­£åœ¨æ·±åº¦åˆ†ææ•°æ®ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ“ æŸ¥è¯¢å·²å‡†å¤‡å®Œæˆ\n\nğŸ§  AIæ­£åœ¨æ·±åº¦åˆ†ææ‚¨çš„æ•°æ®...\n\nâ³ è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™...")
        
        result = agent(full_query)
        
        # æ­¥éª¤4: æ˜¾ç¤ºç»“æœ
        status_placeholder.info("ğŸ“Š æ­£åœ¨æ ¼å¼åŒ–åˆ†æç»“æœ...")
        final_content = f"**ğŸ¯ AIåˆ†æç»“æœ:**\n\n{str(result)}\n\n---\n**âœ… åˆ†æå®Œæˆï¼ˆå¤‡ç”¨æ¨¡å¼ï¼‰**"
        content_placeholder.markdown(final_content)
        
        return str(result)
        
    except Exception as e:
        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        status_placeholder.error(f"âŒ {error_msg}")
        content_placeholder.error(f"**âŒ åˆ†æå¤±è´¥**\n\n{error_msg}\n\nğŸ’¡ å»ºè®®ï¼š\n- æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n- ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸\n- å°è¯•é‡æ–°æé—®")
        return error_msg

def analyze_data_fallback_with_progress(query, data_file_name, content_placeholder, status_placeholder, progress_placeholder, time_placeholder, code_stats_placeholder, start_time):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„å¤‡ç”¨åˆ†ææ–¹æ³•"""
    try:
        # æ­¥éª¤1: åŠ è½½AIå¼•æ“ (30%)
        progress_placeholder.progress(0.3)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - åŠ è½½AIå¼•æ“")
        
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–AIåˆ†æå¼•æ“...")
        from google_ads_anlyst_agent import agent
        
        # æ­¥éª¤2: å‡†å¤‡æŸ¥è¯¢ (50%)
        progress_placeholder.progress(0.5)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - å‡†å¤‡æŸ¥è¯¢")
        
        full_query = f"å½“å‰ç›®å½•{data_file_name}çš„æ–‡ä»¶ï¼Œ{query}"
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ“ æŸ¥è¯¢å·²å‡†å¤‡å®Œæˆ\n\nğŸ§  AIæ­£åœ¨æ·±åº¦åˆ†ææ‚¨çš„æ•°æ®...")
        
        # æ­¥éª¤3: æ‰§è¡Œåˆ†æ (70%-90%)
        progress_placeholder.progress(0.7)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - æ·±åº¦åˆ†æä¸­")
        
        content_placeholder.markdown("**ğŸ¤– å¤‡ç”¨åˆ†ææ¨¡å¼å¯åŠ¨**\n\nğŸ“ æŸ¥è¯¢å·²å‡†å¤‡å®Œæˆ\n\nğŸ§  AIæ­£åœ¨æ·±åº¦åˆ†ææ‚¨çš„æ•°æ®...\n\nâ³ è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™...")
        
        result = agent(full_query)
        
        # æ­¥éª¤4: å®Œæˆ (100%)
        progress_placeholder.progress(1.0)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - å®Œæˆ")
        
        final_content = f"**ğŸ¯ AIåˆ†æç»“æœ:**\n\n{str(result)}\n\n---\n**âœ… åˆ†æå®Œæˆï¼ˆå¤‡ç”¨æ¨¡å¼ï¼‰**"
        content_placeholder.markdown(final_content)
        
        return str(result)
        
    except Exception as e:
        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        progress_placeholder.progress(0.0)
        time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ - å¤±è´¥")
        status_placeholder.error(f"âŒ {error_msg}")
        content_placeholder.error(f"**âŒ åˆ†æå¤±è´¥**\n\n{error_msg}\n\nğŸ’¡ å»ºè®®ï¼š\n- æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n- ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸\n- å°è¯•é‡æ–°æé—®")
        return error_msg



def main():
    # Header
    st.markdown('<h1 class="main-header">ğŸ¤– AIæ•°æ®åˆ†æå¸ˆæ¼”ç¤º</h1>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ç®¡ç†")
        
        # File upload
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæ–‡ä»¶", 
            type=['csv'],
            help="æ”¯æŒCSVæ ¼å¼çš„æ•°æ®æ–‡ä»¶"
        )
        
        if uploaded_file is not None:
            try:
                # Save uploaded file
                file_path = f"uploaded_{uploaded_file.name}"
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # Load data
                df = pd.read_csv(file_path)
                st.session_state.data = df
                st.session_state.current_file_name = file_path
                st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼\n- æ–‡ä»¶å: {uploaded_file.name}\n- æ•°æ®è¡Œæ•°: {len(df)}\n- åˆ—æ•°: {len(df.columns)}")
                
            except Exception as e:
                st.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        
        # Load default data button
        if st.button("ğŸ“Š åŠ è½½ç¤ºä¾‹æ•°æ®"):
            df, filename = load_default_data()
            if df is not None:
                st.session_state.data = df
                st.session_state.current_file_name = filename
                st.success(f"âœ… ç¤ºä¾‹æ•°æ®åŠ è½½æˆåŠŸï¼\n- æ•°æ®è¡Œæ•°: {len(df)}\n- åˆ—æ•°: {len(df.columns)}")
        
        # Data info
        if st.session_state.data is not None:
            st.markdown("---")
            st.subheader("ğŸ“‹ å½“å‰æ•°æ®ä¿¡æ¯")
            df = st.session_state.data
            st.write(f"**æ–‡ä»¶å:** {st.session_state.current_file_name}")
            st.write(f"**è¡Œæ•°:** {len(df):,}")
            st.write(f"**åˆ—æ•°:** {len(df.columns)}")
            st.write(f"**åˆ—åé¢„è§ˆ:**")
            st.write(", ".join(df.columns[:5].tolist()) + ("..." if len(df.columns) > 5 else ""))
            
            # åˆ†æè®¾ç½®
            st.markdown("---")
            st.subheader("âš™ï¸ åˆ†æè®¾ç½®")
            
            # æµå¼è¾“å‡ºå¼€å…³
            enable_streaming = st.checkbox(
                "å¯ç”¨æµå¼è¾“å‡º", 
                value=True, 
                help="å®æ—¶æ˜¾ç¤ºåˆ†æè¿‡ç¨‹ï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥å…³é—­"
            )
            st.session_state.enable_streaming = enable_streaming
            
            # è°ƒè¯•æ¨¡å¼å¼€å…³
            debug_mode = st.checkbox(
                "è°ƒè¯•æ¨¡å¼", 
                value=False, 
                help="æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯"
            )
            st.session_state.debug_mode = debug_mode
            
            # æ•°æ®å¯¼å‡ºé€‰é¡¹
            st.markdown("---")
            st.subheader("ğŸ“¤ æ•°æ®å¯¼å‡º")
            
            # æ•°æ®æ‘˜è¦ä¸‹è½½
            csv_summary = create_csv_summary(df)
            if csv_summary:
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½æ•°æ®æ‘˜è¦",
                    data=csv_summary,
                    file_name=f"æ•°æ®æ‘˜è¦_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            # åŸå§‹æ•°æ®ä¸‹è½½
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False, encoding='utf-8')
            st.download_button(
                label="ğŸ“ ä¸‹è½½åŸå§‹æ•°æ®",
                data=csv_buffer.getvalue(),
                file_name=f"åŸå§‹æ•°æ®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    # Main content
    if st.session_state.data is None:
        # Welcome screen
        st.markdown("""
        <div class="demo-card">
            <h3>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨AIæ•°æ®åˆ†æå¸ˆæ¼”ç¤º</h3>
            <p>è¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°æ®åˆ†æå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ï¼š</p>
            <ul>
                <li>ğŸ“Š è‡ªåŠ¨åˆ†ææ•°æ®ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯</li>
                <li>ğŸ” å›ç­”å…³äºæ•°æ®çš„å„ç§é—®é¢˜</li>
                <li>ğŸ“ˆ ç”Ÿæˆæ•°æ®æ´å¯Ÿå’Œå»ºè®®</li>
                <li>ğŸ’¡ æä¾›ä¸“ä¸šçš„æ•°æ®åˆ†æå»ºè®®</li>
            </ul>
            <p><strong>å¼€å§‹ä½¿ç”¨ï¼š</strong>è¯·åœ¨å·¦ä¾§ä¸Šä¼ CSVæ–‡ä»¶æˆ–åŠ è½½ç¤ºä¾‹æ•°æ®</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Demo features
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ¯ ä¸»è¦åŠŸèƒ½
            - **æ™ºèƒ½é—®ç­”**: ç”¨è‡ªç„¶è¯­è¨€æé—®
            - **æ•°æ®æ´å¯Ÿ**: è‡ªåŠ¨å‘ç°æ•°æ®æ¨¡å¼
            - **ç»Ÿè®¡åˆ†æ**: ä¸“ä¸šçš„ç»Ÿè®¡è®¡ç®—
            - **å¯è§†åŒ–å»ºè®®**: æ¨èåˆé€‚çš„å›¾è¡¨
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ“ ç¤ºä¾‹é—®é¢˜
            - "è¿™ä¸ªæ•°æ®é›†æœ‰å¤šå°‘è¡Œæ•°æ®ï¼Ÿ"
            - "å“ªä¸ªå¹¿å‘Šç³»åˆ—æ•ˆæœæœ€å¥½ï¼Ÿ"
            - "ä¸åŒè®¾å¤‡çš„è½¬åŒ–ç‡å¦‚ä½•ï¼Ÿ"
            - "æ•°æ®ä¸­æœ‰ç¼ºå¤±å€¼å—ï¼Ÿ"
            """)
    
    else:
        # Data loaded - show analysis interface
        df = st.session_state.data
        
        # Data overview
        st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»è¡Œæ•°", f"{len(df):,}")
        with col2:
            st.metric("æ€»åˆ—æ•°", len(df.columns))
        with col3:
            # Calculate missing values
            missing_count = df.isnull().sum().sum()
            st.metric("ç¼ºå¤±å€¼", missing_count)
        with col4:
            # Calculate numeric columns
            numeric_cols = df.select_dtypes(include=['number']).columns
            st.metric("æ•°å€¼åˆ—", len(numeric_cols))
        
        # Sample data
        with st.expander("ğŸ“‹ æŸ¥çœ‹æ•°æ®æ ·æœ¬", expanded=False):
            st.dataframe(df.head(10), use_container_width=True)
        
        # Analysis section
        st.markdown("---")
        st.subheader("ğŸ¤– AIæ™ºèƒ½åˆ†æ")
        
        # Predefined questions
        st.markdown("**ğŸ’¡ å¿«é€Ÿåˆ†æé€‰é¡¹:**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š æ•°æ®åŸºæœ¬ç»Ÿè®¡"):
                st.session_state.selected_query = "è¯·åˆ†æè¿™ä¸ªæ•°æ®é›†çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ•°æ®è§„æ¨¡ã€æ•°æ®ç±»å‹ã€ç¼ºå¤±å€¼æƒ…å†µç­‰"
        
        with col2:
            if st.button("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥"):
                st.session_state.selected_query = "è¯·æ£€æŸ¥æ•°æ®è´¨é‡ï¼ŒåŒ…æ‹¬ç¼ºå¤±å€¼ã€é‡å¤å€¼ã€å¼‚å¸¸å€¼ç­‰é—®é¢˜"
        
        with col3:
            if st.button("ğŸ“ˆ å…³é”®æŒ‡æ ‡åˆ†æ"):
                st.session_state.selected_query = "è¯·åˆ†ææ•°æ®ä¸­çš„å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼Œæ‰¾å‡ºé‡è¦çš„æ•°æ®æ´å¯Ÿ"
        
        # Custom query input
        st.markdown("**âœï¸ è‡ªå®šä¹‰é—®é¢˜:**")
        user_query = st.text_area(
            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:",
            placeholder="ä¾‹å¦‚ï¼šå¸®æˆ‘åˆ†æä¸åŒè®¾å¤‡ç±»å‹çš„è½¬åŒ–ç‡å·®å¼‚",
            height=100,
            key="user_query"
        )
        
        # Analysis button
        col1, col2 = st.columns([1, 4])
        with col1:
            analyze_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary")
        
        # Handle analysis
        query_to_analyze = None
        if analyze_button and user_query.strip():
            query_to_analyze = user_query.strip()
        elif hasattr(st.session_state, 'selected_query'):
            query_to_analyze = st.session_state.selected_query
            delattr(st.session_state, 'selected_query')
        
        if query_to_analyze:
            st.markdown("---")
            st.subheader("ğŸ“‹ åˆ†æç»“æœ")
            
            # Show query
            st.markdown(f"**â“ åˆ†æé—®é¢˜:** {query_to_analyze}")
            
            # åˆ›å»ºåˆ†ææ˜¾ç¤ºåŒºåŸŸ
            st.markdown("### ğŸ” åˆ†æè¿‡ç¨‹")
            
            # çŠ¶æ€æ 
            st.markdown('<div class="status-row">', unsafe_allow_html=True)
            status_col1, status_col2, status_col3 = st.columns([2, 2, 2])
            
            with status_col1:
                status_placeholder = st.empty()
                status_placeholder.info("ğŸš€ å‡†å¤‡å¼€å§‹åˆ†æ...")
            
            with status_col2:
                time_placeholder = st.empty()
                time_placeholder.markdown('<div class="analysis-status"><strong>â±ï¸ åˆ†ææ—¶é—´:</strong> å‡†å¤‡ä¸­...</div>', unsafe_allow_html=True)
            
            with status_col3:
                code_stats_placeholder = st.empty()
                code_stats_placeholder.markdown('<div class="analysis-status"><strong>ğŸ ä»£ç æ‰§è¡Œ:</strong> ç­‰å¾…ä¸­...</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # è¿›åº¦æ¡
            progress_placeholder = st.empty()
            progress_placeholder.progress(0.0)
            
            # åˆ†æè®¾ç½®ä¿¡æ¯
            with st.expander("âš™ï¸ åˆ†æè®¾ç½®", expanded=False):
                setting_col1, setting_col2, setting_col3 = st.columns(3)
                with setting_col1:
                    st.write(f"**æµå¼è¾“å‡º:** {'âœ… å¯ç”¨' if st.session_state.get('enable_streaming', True) else 'âŒ ç¦ç”¨'}")
                with setting_col2:
                    st.write(f"**è°ƒè¯•æ¨¡å¼:** {'âœ… å¯ç”¨' if st.session_state.get('debug_mode', False) else 'âŒ ç¦ç”¨'}")
                with setting_col3:
                    st.write(f"**æ•°æ®æ–‡ä»¶:** `{st.session_state.current_file_name}`")
            
            # ä¸»è¦å†…å®¹æ˜¾ç¤ºåŒºåŸŸ
            st.markdown("### ğŸ“Š åˆ†æå†…å®¹")
            content_container = st.container()
            with content_container:
                content_placeholder = st.empty()
                content_placeholder.markdown('<div class="code-execution"><strong>ğŸš€ å‡†å¤‡å¼€å§‹åˆ†æ...</strong><br/>è¯·ç¨å€™ï¼ŒAIæ­£åœ¨å‡†å¤‡åˆ†ææ‚¨çš„æ•°æ®</div>', unsafe_allow_html=True)
            
            # åˆ†æå¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            try:
                # æ˜¾ç¤ºå¼€å§‹çŠ¶æ€
                status_placeholder.info("ğŸš€ å¼€å§‹åˆ†æ...")
                progress_placeholder.progress(0.1)
                time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’")
                
                # æ ¹æ®ç”¨æˆ·è®¾ç½®é€‰æ‹©åˆ†ææ–¹å¼
                if st.session_state.get('enable_streaming', True):
                    # æµå¼åˆ†æ
                    progress_placeholder.progress(0.2)
                    time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ (æµå¼æ¨¡å¼)")
                    
                    result = analyze_data_with_agent_streaming_with_progress(
                        query_to_analyze, 
                        st.session_state.current_file_name,
                        content_placeholder,
                        status_placeholder,
                        progress_placeholder,
                        time_placeholder,
                        code_stats_placeholder,
                        start_time
                    )
                else:
                    # éæµå¼åˆ†æ
                    progress_placeholder.progress(0.3)
                    time_placeholder.markdown(f"**â±ï¸ åˆ†ææ—¶é—´:** {(datetime.now() - start_time).total_seconds():.1f}ç§’ (å¤‡ç”¨æ¨¡å¼)")
                    
                    result = analyze_data_fallback_with_progress(
                        query_to_analyze,
                        st.session_state.current_file_name,
                        content_placeholder,
                        status_placeholder,
                        progress_placeholder,
                        time_placeholder,
                        code_stats_placeholder,
                        start_time
                    )
                
                # è®¡ç®—åˆ†ææ—¶é—´
                end_time = datetime.now()
                analysis_duration = (end_time - start_time).total_seconds()
                
                # æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                progress_placeholder.progress(1.0)
                status_placeholder.success(f"âœ… åˆ†æå®Œæˆï¼")
                time_placeholder.markdown(f"**â±ï¸ æ€»ç”¨æ—¶:** {analysis_duration:.1f}ç§’ âœ…")
                
                # æ˜¾ç¤ºåˆ†æç»Ÿè®¡
                st.markdown("---")
                
                # ç´§å‡‘çš„ç»Ÿè®¡æ˜¾ç¤º
                result_length = len(str(result)) if result else 0
                words_per_second = result_length / analysis_duration if analysis_duration > 0 else 0
                
                stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                
                with stat_col1:
                    st.metric("â±ï¸ åˆ†æç”¨æ—¶", f"{analysis_duration:.1f}ç§’")
                
                with stat_col2:
                    st.metric("ğŸ”„ åˆ†ææ¨¡å¼", "æµå¼" if st.session_state.get('enable_streaming', True) else "å¤‡ç”¨")
                
                with stat_col3:
                    st.metric("ğŸ“ ç»“æœé•¿åº¦", f"{result_length:,}å­—ç¬¦")
                
                with stat_col4:
                    st.metric("âš¡ ç”Ÿæˆé€Ÿåº¦", f"{words_per_second:.0f}å­—ç¬¦/ç§’")
                
                # è°ƒè¯•ä¿¡æ¯
                if st.session_state.get('debug_mode', False):
                    with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯", expanded=False):
                        st.write(f"**åˆ†æç»Ÿè®¡:**")
                        st.write(f"- å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
                        st.write(f"- ç»“æŸæ—¶é—´: {end_time.strftime('%H:%M:%S')}")
                        st.write(f"- åˆ†æç”¨æ—¶: {analysis_duration:.2f}ç§’")
                        st.write(f"- æµå¼è¾“å‡º: {'å¯ç”¨' if st.session_state.get('enable_streaming', True) else 'ç¦ç”¨'}")
                        st.write(f"- ç»“æœé•¿åº¦: {len(str(result))} å­—ç¬¦")
                        st.write(f"- æ•°æ®æ–‡ä»¶: {st.session_state.current_file_name}")
                        
                        # æ˜¾ç¤ºç»“æœçš„å‰100ä¸ªå­—ç¬¦
                        if result:
                            st.write(f"**ç»“æœé¢„è§ˆ:**")
                            st.code(str(result)[:200] + "..." if len(str(result)) > 200 else str(result))
                
                # åˆ†æè¿‡ç¨‹æ—¶é—´çº¿
                if st.session_state.get('debug_mode', False):
                    with st.expander("â±ï¸ åˆ†ææ—¶é—´çº¿", expanded=False):
                        timeline_data = [
                            {"æ­¥éª¤": "å¼€å§‹åˆ†æ", "æ—¶é—´": start_time.strftime('%H:%M:%S.%f')[:-3], "çŠ¶æ€": "âœ…"},
                            {"æ­¥éª¤": "åˆ›å»ºAIä»£ç†", "æ—¶é—´": (start_time + pd.Timedelta(seconds=0.5)).strftime('%H:%M:%S.%f')[:-3], "çŠ¶æ€": "âœ…"},
                            {"æ­¥éª¤": "å‡†å¤‡æŸ¥è¯¢", "æ—¶é—´": (start_time + pd.Timedelta(seconds=1.0)).strftime('%H:%M:%S.%f')[:-3], "çŠ¶æ€": "âœ…"},
                            {"æ­¥éª¤": "æ‰§è¡Œåˆ†æ", "æ—¶é—´": (start_time + pd.Timedelta(seconds=2.0)).strftime('%H:%M:%S.%f')[:-3], "çŠ¶æ€": "âœ…"},
                            {"æ­¥éª¤": "å®Œæˆåˆ†æ", "æ—¶é—´": end_time.strftime('%H:%M:%S.%f')[:-3], "çŠ¶æ€": "âœ…"}
                        ]
                        
                        timeline_df = pd.DataFrame(timeline_data)
                        st.dataframe(timeline_df, use_container_width=True)
                
                # Save to history
                st.session_state.analysis_history.append({
                    'timestamp': datetime.now(),
                    'query': query_to_analyze,
                    'result': result,
                    'file_name': st.session_state.current_file_name
                })
                
                # æ·»åŠ ä¸‹è½½æŒ‰é’®
                if result and len(result.strip()) > 0:
                    st.markdown("---")
                    st.subheader("ğŸ“¥ ä¸‹è½½é€‰é¡¹")
                    
                    col_download1, col_download2, col_download3 = st.columns(3)
                    
                    with col_download1:
                        # Markdownæ ¼å¼æŠ¥å‘Š
                        markdown_report = create_analysis_report_text(
                            query_to_analyze, 
                            result, 
                            st.session_state.current_file_name
                        )
                        st.download_button(
                            label="ğŸ“„ ä¸‹è½½MarkdownæŠ¥å‘Š",
                            data=markdown_report,
                            file_name=f"åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with col_download2:
                        # JSONæ ¼å¼æŠ¥å‘Š
                        json_report = create_json_report({
                            'query': query_to_analyze,
                            'result': result,
                            'file_name': st.session_state.current_file_name
                        })
                        if json_report:
                            st.download_button(
                                label="ğŸ“Š ä¸‹è½½JSONæŠ¥å‘Š",
                                data=json_report,
                                file_name=f"åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                mime="application/json",
                                use_container_width=True
                            )
                    
                    with col_download3:
                        # æ•°æ®æ‘˜è¦CSV
                        if st.session_state.data is not None:
                            csv_summary = create_csv_summary(st.session_state.data)
                            if csv_summary:
                                st.download_button(
                                    label="ğŸ“ˆ ä¸‹è½½æ•°æ®æ‘˜è¦",
                                    data=csv_summary,
                                    file_name=f"æ•°æ®æ‘˜è¦_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv",
                                    use_container_width=True
                                )
                    
                    # ç»§ç»­åˆ†ææŒ‰é’®
                    if st.button("ğŸ”„ ç»§ç»­åˆ†æ", use_container_width=True):
                        st.rerun()
                
            except Exception as e:
                status_placeholder.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        
        # Analysis history
        if st.session_state.analysis_history:
            st.markdown("---")
            st.subheader("ğŸ“š åˆ†æå†å²")
            
            # å†å²è®°å½•æ“ä½œæŒ‰é’®
            col_hist1, col_hist2, col_hist3 = st.columns(3)
            
            with col_hist1:
                # å¯¼å‡ºæ‰€æœ‰å†å²è®°å½•
                history_export = create_history_export(st.session_state.analysis_history)
                if history_export:
                    st.download_button(
                        label="ğŸ“¥ å¯¼å‡ºå…¨éƒ¨å†å²",
                        data=history_export,
                        file_name=f"åˆ†æå†å²_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
            
            with col_hist2:
                # å¯¼å‡ºæœ€è¿‘5æ¡è®°å½•
                recent_history = st.session_state.analysis_history[-5:]
                recent_export = create_history_export(recent_history)
                if recent_export:
                    st.download_button(
                        label="ğŸ“‹ å¯¼å‡ºæœ€è¿‘è®°å½•",
                        data=recent_export,
                        file_name=f"æœ€è¿‘åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
            
            with col_hist3:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", use_container_width=True):
                    st.session_state.analysis_history = []
                    st.success("å†å²è®°å½•å·²æ¸…ç©ºï¼")
                    st.rerun()
            
            # æ˜¾ç¤ºå†å²è®°å½•
            for i, analysis in enumerate(reversed(st.session_state.analysis_history[-5:])):  # Show last 5
                with st.expander(f"ğŸ” {analysis['query'][:50]}..." if len(analysis['query']) > 50 else f"ğŸ” {analysis['query']}"):
                    st.write(f"**æ—¶é—´:** {analysis['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                    st.write(f"**æ–‡ä»¶:** {analysis['file_name']}")
                    st.write(f"**é—®é¢˜:** {analysis['query']}")
                    st.write(f"**ç»“æœ:** {analysis['result']}")
                    
                    # å•ä¸ªè®°å½•çš„ä¸‹è½½æŒ‰é’®
                    col_single1, col_single2 = st.columns(2)
                    with col_single1:
                        single_report = create_analysis_report_text(
                            analysis['query'], 
                            analysis['result'], 
                            analysis['file_name']
                        )
                        st.download_button(
                            label="ğŸ“„ ä¸‹è½½æ­¤æŠ¥å‘Š",
                            data=single_report,
                            file_name=f"å•ä¸ªåˆ†æ_{analysis['timestamp'].strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown",
                            key=f"download_single_{i}",
                            use_container_width=True
                        )
                    
                    with col_single2:
                        single_json = create_json_report({
                            'query': analysis['query'],
                            'result': analysis['result'],
                            'file_name': analysis['file_name']
                        })
                        if single_json:
                            st.download_button(
                                label="ğŸ“Š ä¸‹è½½JSON",
                                data=single_json,
                                file_name=f"å•ä¸ªåˆ†æ_{analysis['timestamp'].strftime('%Y%m%d_%H%M%S')}.json",
                                mime="application/json",
                                key=f"download_json_{i}",
                                use_container_width=True
                            )
    
    # Footer
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #666; padding: 1rem;'>"
        "ğŸ¤– AIæ•°æ®åˆ†æå¸ˆæ¼”ç¤º - è®©æ•°æ®åˆ†æå˜å¾—ç®€å•é«˜æ•ˆ"
        "</div>", 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()